#!/usr/bin/env python3
"""
Script d'automatisation : Basecamp ‚Üí Google Sheets
Synchronise automatiquement les todos Basecamp vers vos Google Sheets
Bas√© sur la pagination compl√®te d√©velopp√©e dans retrieve_todos_by_group.py
"""

import os
import sys
import json
import logging
from datetime import datetime
from typing import Dict, List, Optional, Any
from pathlib import Path

# Import du convertisseur de dates avanc√©
from date_converter import BasecampDateConverter

# Ajouter le chemin backend pour imports
backend_path = Path(__file__).parent.parent
sys.path.append(str(backend_path))

from app.core.config import settings
from app.services.google_sheets_write_service import GoogleSheetsWriteService
from retrieve_todos_by_group import BasecampTodoGroupRetriever

# Configuration logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class BasecampToSheetsSync:
    """Synchronisation automatique Basecamp ‚Üí Google Sheets"""
    
    def __init__(self):
        self.basecamp_retriever = BasecampTodoGroupRetriever()
        self.sheets_service = GoogleSheetsWriteService()
        self.date_converter = BasecampDateConverter()
        
        # Mapping des noms de groupes Basecamp vers les sheets Google
        self.group_to_sheet_mapping = {
            "Marketing, Communication, RP": "Marketing Communication RP",
            "IT": "IT", 
            "Money": "Money",
            "Administration / Management": "Administration-management",
            "Produit": "Produit",
            "Op√©rations": "Op√©rations",
            "Commercial": "Commercial",
            "Partenariats": "Partenariats",
            "Design & Branding": "Design & Branding",
            "Investors": "Investors",
            "Prestataires": "Prestataires",
            "Ressources mat√©rielles": "Ressources Mat√©rielles",  # Correspondance exacte
            "Capital Humain - Stages": "Capital Humain - Stages",
            "Capital Humain": "Capital Humain",  # Nouveau
            "Agrifrika - Copyright": "Agrifika-Copyright",
            "Abaca Assessment - Investment Readiness Tool": "Abaca Assessment",
            "Acc√©l√©ration / D√©veloppement": "Acc√©l√©ration D√©veloppement"  # Nouveau
        }
    
    def transform_basecamp_todo_to_sheets_row(self, todo: Dict[str, Any]) -> List[str]:
        """Transforme un todo Basecamp en ligne Google Sheets"""
        try:
            # Mapping des champs
            todo_id = str(todo.get('id', ''))
            title = todo.get('content', todo.get('title', ''))
            
            # Mapping du statut
            completed = todo.get('completed', False)
            status = "completed" if completed else "pending"
            
            # Assign√© √† (extraire les noms depuis les donn√©es assign√©es)
            assigned_to = ""
            assignees = todo.get('assignees', [])
            if assignees:
                # Prendre les noms de tous les assign√©s et les joindre avec des virgules
                names = [assignee.get('name', '') for assignee in assignees if assignee.get('name')]
                assigned_to = ', '.join(names)
            
            # Date d'√©ch√©ance avec convertisseur avanc√©
            due_date = ""
            due_on = todo.get('due_on')
            if due_on:
                # Utiliser le convertisseur avanc√© pour une conversion robuste
                due_date = self.date_converter.convert_to_format(due_on, 'google_sheets_fr')
                
                # Log pour debug si conversion √©choue
                if due_date == due_on:  # Pas de conversion effectu√©e
                    validation = self.date_converter.validate_date(due_on)
                    if not validation['is_valid']:
                        logger.warning(f"Date non convertie pour todo {todo.get('id', 'unknown')}: '{due_on}' - Erreurs: {validation['errors']}")
                else:
                    logger.debug(f"Date convertie: '{due_on}' ‚Üí '{due_date}'")
            
            return [todo_id, title, status, assigned_to, due_date]
            
        except Exception as e:
            logger.warning(f"Erreur lors de la transformation du todo {todo.get('id', 'unknown')}: {e}")
            return []
    
    def clear_sheet_data(self, sheet_name: str) -> bool:
        """Vide les donn√©es d'un sheet (garde les headers)"""
        try:
            range_name = f"{sheet_name}!A2:E500"
            return self.sheets_service.clear_range(settings.TODOS_SHEET_ID, range_name)
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors du vidage du sheet '{sheet_name}': {e}")
            return False
    
    def write_todos_to_sheet(self, sheet_name: str, todos: List[Dict[str, Any]]) -> bool:
        """√âcrit les todos dans un sheet Google"""
        try:
            if not todos:
                logger.info(f"Aucun todo √† √©crire pour '{sheet_name}'")
                return True
            
            # Transformer les todos en lignes
            rows = []
            for todo in todos:
                row = self.transform_basecamp_todo_to_sheets_row(todo)
                if row:
                    rows.append(row)
            
            if not rows:
                logger.warning(f"Aucune ligne valide √† √©crire pour '{sheet_name}'")
                return True
            
            # Limiter √† 499 lignes maximum (A2:E500)
            rows = rows[:499]
            
            # Construire le range
            end_row = len(rows) + 1  # +1 car on commence √† A2
            range_name = f"{sheet_name}!A2:E{end_row}"
            
            body = {
                'values': rows
            }
            
            result = self.sheets_service.service.spreadsheets().values().update(
                spreadsheetId=settings.TODOS_SHEET_ID,
                range=range_name,
                valueInputOption='RAW',
                body=body
            ).execute()
            
            updated_cells = result.get('updatedCells', 0)
            logger.info(f"‚úÖ '{sheet_name}': {len(rows)} todos √©crits ({updated_cells} cellules mises √† jour)")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'√©criture dans '{sheet_name}': {e}")
            return False
    
    def sync_group_to_sheet(self, basecamp_group: str, sheet_name: str) -> Dict[str, Any]:
        """Synchronise un groupe Basecamp vers un sheet Google"""
        try:
            logger.info(f"üîÑ Synchronisation: '{basecamp_group}' ‚Üí '{sheet_name}'")
            
            # R√©cup√©rer les todos depuis Basecamp
            basecamp_data = self.basecamp_retriever.get_todos_for_groups([basecamp_group])
            
            if not basecamp_data or 'groups' not in basecamp_data:
                logger.warning(f"Aucune donn√©e Basecamp trouv√©e pour '{basecamp_group}'")
                return {'success': False, 'error': 'No Basecamp data'}
            
            # Extraire les todos du groupe
            group_data = None
            for group in basecamp_data['groups']:
                if group['name'] == basecamp_group:
                    group_data = group
                    break
            
            if not group_data:
                logger.warning(f"Groupe '{basecamp_group}' non trouv√© dans les donn√©es Basecamp")
                return {'success': False, 'error': 'Group not found'}
            
            todos = group_data.get('todos', [])
            
            # Vider le sheet et √©crire les nouveaux todos
            if self.clear_sheet_data(sheet_name):
                if self.write_todos_to_sheet(sheet_name, todos):
                    return {
                        'success': True,
                        'todos_count': len(todos),
                        'basecamp_group': basecamp_group,
                        'sheet_name': sheet_name
                    }
            
            return {'success': False, 'error': 'Write operation failed'}
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la synchronisation '{basecamp_group}' ‚Üí '{sheet_name}': {e}")
            return {'success': False, 'error': str(e)}
    
    def detect_missing_categories(self) -> Dict[str, Any]:
        """D√©tecte les cat√©gories Basecamp qui n'existent pas encore dans Google Sheets"""
        try:
            logger.info("üîç D√©tection des cat√©gories manquantes...")
            
            # R√©cup√©rer tous les groupes Basecamp disponibles
            basecamp_groups = self.basecamp_retriever.get_available_groups_data()
            basecamp_names = [group['name'] for group in basecamp_groups]
            
            # R√©cup√©rer tous les onglets Google Sheets existants
            existing_sheets = self.sheets_service.list_all_sheets(settings.TODOS_SHEET_ID)
            
            # Identifier les correspondances manquantes
            missing_in_sheets = []
            missing_in_mapping = []
            
            for basecamp_name in basecamp_names:
                # V√©rifier si on a un mapping pour ce groupe
                if basecamp_name not in self.group_to_sheet_mapping:
                    missing_in_mapping.append(basecamp_name)
                    continue
                
                # V√©rifier si l'onglet existe dans Google Sheets
                expected_sheet_name = self.group_to_sheet_mapping[basecamp_name]
                if expected_sheet_name not in existing_sheets:
                    missing_in_sheets.append({
                        'basecamp_group': basecamp_name,
                        'expected_sheet': expected_sheet_name
                    })
            
            return {
                'basecamp_groups': basecamp_names,
                'existing_sheets': existing_sheets,
                'missing_in_sheets': missing_in_sheets,
                'missing_in_mapping': missing_in_mapping,
                'analysis_complete': True
            }
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la d√©tection des cat√©gories manquantes: {e}")
            return {'analysis_complete': False, 'error': str(e)}
    
    def create_missing_sheets(self, detection_result: Dict[str, Any]) -> Dict[str, Any]:
        """Cr√©e automatiquement les onglets manquants avec headers"""
        try:
            if not detection_result.get('analysis_complete'):
                return {'success': False, 'error': 'Analysis not complete'}
            
            missing_sheets = detection_result.get('missing_in_sheets', [])
            
            if not missing_sheets:
                logger.info("‚úÖ Aucun onglet manquant d√©tect√©")
                return {'success': True, 'created_sheets': []}
            
            # Headers standards pour tous les onglets todos
            headers = ["ID", "Title", "Status", "Assigned_To", "Due_Date"]
            created_sheets = []
            failed_sheets = []
            
            for missing in missing_sheets:
                sheet_name = missing['expected_sheet']
                basecamp_group = missing['basecamp_group']
                
                logger.info(f"üîß Cr√©ation de l'onglet '{sheet_name}' pour le groupe '{basecamp_group}'")
                
                if self.sheets_service.create_sheet_with_headers(settings.TODOS_SHEET_ID, sheet_name, headers):
                    created_sheets.append({
                        'sheet_name': sheet_name,
                        'basecamp_group': basecamp_group
                    })
                    logger.info(f"‚úÖ Onglet '{sheet_name}' cr√©√© avec succ√®s")
                else:
                    failed_sheets.append({
                        'sheet_name': sheet_name,
                        'basecamp_group': basecamp_group
                    })
                    logger.error(f"‚ùå √âchec cr√©ation onglet '{sheet_name}'")
            
            return {
                'success': True,
                'created_sheets': created_sheets,
                'failed_sheets': failed_sheets,
                'total_created': len(created_sheets),
                'total_failed': len(failed_sheets)
            }
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la cr√©ation des onglets manquants: {e}")
            return {'success': False, 'error': str(e)}
    
    def sync_all_groups(self, groups_filter: Optional[List[str]] = None, auto_create_sheets: bool = True) -> Dict[str, Any]:
        """Synchronise tous les groupes ou une liste filtr√©e"""
        try:
            logger.info("üöÄ D√©but de la synchronisation compl√®te Basecamp ‚Üí Google Sheets")
            
            # √âtape 1: D√©tection et cr√©ation automatique des onglets manquants
            creation_result = {'created_sheets': [], 'failed_sheets': []}
            if auto_create_sheets:
                logger.info("üîç V√©rification des cat√©gories manquantes...")
                detection_result = self.detect_missing_categories()
                
                if detection_result.get('analysis_complete'):
                    missing_sheets = detection_result.get('missing_in_sheets', [])
                    missing_mappings = detection_result.get('missing_in_mapping', [])
                    
                    if missing_sheets:
                        logger.info(f"üìã Onglets manquants d√©tect√©s: {len(missing_sheets)}")
                        creation_result = self.create_missing_sheets(detection_result)
                    
                    if missing_mappings:
                        logger.warning(f"‚ö†Ô∏è Groupes sans mapping d√©tect√©s: {missing_mappings}")
                        logger.warning("Ces groupes seront ignor√©s dans la synchronisation")
                else:
                    logger.warning("‚ö†Ô∏è √âchec de la d√©tection des cat√©gories manquantes")
            
            # √âtape 2: D√©terminer les groupes √† synchroniser
            groups_to_sync = groups_filter or list(self.group_to_sheet_mapping.keys())
            
            results = {
                'sync_timestamp': datetime.now().isoformat(),
                'total_groups': len(groups_to_sync),
                'successful_syncs': 0,
                'failed_syncs': 0,
                'details': []
            }
            
            for basecamp_group in groups_to_sync:
                sheet_name = self.group_to_sheet_mapping.get(basecamp_group)
                
                if not sheet_name:
                    logger.warning(f"‚ö†Ô∏è  Aucun mapping trouv√© pour le groupe '{basecamp_group}'")
                    results['details'].append({
                        'basecamp_group': basecamp_group,
                        'success': False,
                        'error': 'No sheet mapping found'
                    })
                    results['failed_syncs'] += 1
                    continue
                
                # Synchroniser ce groupe
                sync_result = self.sync_group_to_sheet(basecamp_group, sheet_name)
                results['details'].append(sync_result)
                
                if sync_result['success']:
                    results['successful_syncs'] += 1
                    logger.info(f"‚úÖ Synchronisation r√©ussie: '{basecamp_group}' ({sync_result.get('todos_count', 0)} todos)")
                else:
                    results['failed_syncs'] += 1
                    logger.error(f"‚ùå √âchec synchronisation: '{basecamp_group}' - {sync_result.get('error', 'Unknown error')}")
            
            # R√©sum√© final
            success_rate = (results['successful_syncs'] / results['total_groups']) * 100
            logger.info(f"üéØ Synchronisation termin√©e: {results['successful_syncs']}/{results['total_groups']} groupes r√©ussis ({success_rate:.1f}%)")
            
            # Statistiques de conversion des dates
            date_stats = self.date_converter.get_conversion_stats()
            if date_stats['total_conversions'] > 0:
                logger.info(f"üìÖ Dates converties: {date_stats['successful_conversions']}/{date_stats['total_conversions']} ({date_stats['success_rate']}%)")
                if date_stats['formats_detected']:
                    logger.info(f"üìã Formats d√©tect√©s: {', '.join(date_stats['formats_detected'].keys())}")
            
            # Ajouter les stats de dates au r√©sultat
            results['date_conversion_stats'] = date_stats
            
            return results
            
        except Exception as e:
            logger.error(f"‚ùå Erreur critique lors de la synchronisation compl√®te: {e}")
            return {
                'success': False,
                'error': str(e),
                'sync_timestamp': datetime.now().isoformat()
            }
    
    def create_headers_if_missing(self, sheet_name: str) -> bool:
        """Cr√©e les headers dans un sheet s'ils sont manquants"""
        try:
            # Headers standard
            headers = ["ID", "Title", "Status", "Assigned_To", "Due_Date"]
            
            range_name = f"{sheet_name}!A1:E1"
            body = {
                'values': [headers]
            }
            
            result = self.sheets_service.service.spreadsheets().values().update(
                spreadsheetId=settings.TODOS_SHEET_ID,
                range=range_name,
                valueInputOption='RAW',
                body=body
            ).execute()
            
            logger.info(f"‚úÖ Headers cr√©√©s pour '{sheet_name}'")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la cr√©ation des headers pour '{sheet_name}': {e}")
            return False

def main():
    """Fonction principale avec options CLI"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Synchronisation Basecamp ‚Üí Google Sheets")
    parser.add_argument('--groups', nargs='*', help='Groupes sp√©cifiques √† synchroniser')
    parser.add_argument('--create-headers', action='store_true', help='Cr√©er les headers dans tous les sheets')
    parser.add_argument('--dry-run', action='store_true', help='Mode test sans √©criture')
    parser.add_argument('--output', help='Fichier de sortie pour le rapport JSON')
    parser.add_argument('--detect-missing', action='store_true', help='D√©tecter les cat√©gories manquantes seulement')
    parser.add_argument('--create-missing', action='store_true', help='Cr√©er les onglets manquants seulement')
    parser.add_argument('--no-auto-create', action='store_true', help='D√©sactiver la cr√©ation automatique des onglets')
    
    args = parser.parse_args()
    
    syncer = BasecampToSheetsSync()
    
    try:
        # D√©tection des cat√©gories manquantes seulement
        if args.detect_missing:
            logger.info("üîç D√©tection des cat√©gories manquantes uniquement...")
            detection_result = syncer.detect_missing_categories()
            
            if detection_result.get('analysis_complete'):
                print(f"\n=== ANALYSE DES CATEGORIES ===")
                print(f"Groupes Basecamp: {len(detection_result['basecamp_groups'])}")
                print(f"Onglets Google Sheets: {len(detection_result['existing_sheets'])}")
                print(f"Onglets manquants: {len(detection_result['missing_in_sheets'])}")
                print(f"Groupes sans mapping: {len(detection_result['missing_in_mapping'])}")
                
                if detection_result['missing_in_sheets']:
                    print(f"\n=== ONGLETS A CREER ===")
                    for missing in detection_result['missing_in_sheets']:
                        print(f"  - {missing['expected_sheet']} (pour {missing['basecamp_group']})")
                
                if detection_result['missing_in_mapping']:
                    print(f"\n=== GROUPES SANS MAPPING ===")
                    for group in detection_result['missing_in_mapping']:
                        print(f"  - {group}")
                        
                print(f"\n=== GROUPES BASECAMP DETECTES ===")
                for group in detection_result['basecamp_groups'][:5]:  # Premiers 5 seulement
                    print(f"  - {group}")
                if len(detection_result['basecamp_groups']) > 5:
                    print(f"  ... et {len(detection_result['basecamp_groups']) - 5} autres")
                    
                print(f"\n=== ONGLETS GOOGLE SHEETS EXISTANTS ===")
                for sheet in detection_result['existing_sheets']:
                    print(f"  - {sheet}")
            return
        
        # Cr√©ation des onglets manquants seulement  
        if args.create_missing:
            logger.info("üîß Cr√©ation des onglets manquants uniquement...")
            detection_result = syncer.detect_missing_categories()
            
            if detection_result.get('analysis_complete'):
                creation_result = syncer.create_missing_sheets(detection_result)
                print(f"\nüîß CR√âATION D'ONGLETS")
                print(f"Onglets cr√©√©s: {creation_result.get('total_created', 0)}")
                print(f"√âchecs: {creation_result.get('total_failed', 0)}")
                
                for created in creation_result.get('created_sheets', []):
                    print(f"  ‚úÖ {created['sheet_name']}")
                    
                for failed in creation_result.get('failed_sheets', []):
                    print(f"  ‚ùå {failed['sheet_name']}")
            return
        
        # Cr√©er les headers si demand√©
        if args.create_headers:
            logger.info("üîß Cr√©ation des headers dans tous les sheets...")
            for sheet_name in settings.TODOS_SHEET_NAMES:
                syncer.create_headers_if_missing(sheet_name)
            logger.info("‚úÖ Headers cr√©√©s avec succ√®s")
        
        # Mode dry-run
        if args.dry_run:
            logger.info("üß™ Mode DRY-RUN activ√© - Aucune √©criture ne sera effectu√©e")
            # Ici on pourrait juste afficher ce qui serait synchronis√©
            return
        
        # Synchronisation avec ou sans auto-cr√©ation
        auto_create = not args.no_auto_create
        results = syncer.sync_all_groups(args.groups, auto_create_sheets=auto_create)
        
        # Sauvegarder le rapport si demand√©
        if args.output:
            with open(args.output, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False)
            logger.info(f"üìÑ Rapport sauvegard√© dans '{args.output}'")
        
        # Afficher le r√©sum√©
        print(f"\nüéØ R√âSUM√â DE LA SYNCHRONISATION")
        print(f"Groupes trait√©s: {results['total_groups']}")
        print(f"R√©ussites: {results['successful_syncs']}")
        print(f"√âchecs: {results['failed_syncs']}")
        print(f"Taux de r√©ussite: {(results['successful_syncs']/results['total_groups']*100):.1f}%")
        
    except Exception as e:
        logger.error(f"‚ùå Erreur critique: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()